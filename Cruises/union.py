# union.py
from core.libs    import pd, warnings, Path, os
from Cruises.utils.extractors import extract_metadata_from_excel
from core.schema import COLUMNS, cast_dataframe
from Cruises.utils.cleaners import get_column
from Cruises.utils.normalizers import clean_column_name
from tqdm import tqdm
import traceback
from Cruises.onedriver import force_download

warnings.filterwarnings(
    "ignore",
    message="Data Validation extension is not supported and will be removed",
    category=UserWarning,
    module="openpyxl",
)
warnings.filterwarnings(
    "ignore",
    message="Conditional Formatting extension is not supported and will be removed",
    category=UserWarning,
    module="openpyxl",
)
warnings.filterwarnings(
    "ignore",
    message="The behavior of DataFrame concatenation with empty or all-NA entries is deprecated",
    category=FutureWarning,
    module="pandas.core.reshape.concat"
)

def read_metadata_and_input(file_path: str) -> tuple[pd.DataFrame | None, dict]:
    """
    Abre un XLSX, extrae:
     - df_input: la hoja 'Input' o 'DataInput'
     - meta: dict con contract_code, farmer_name, cruise_date
    """
    from pathlib import Path
    from time import sleep

    try:
        path = Path(file_path)
        max_retries = 3
        delay_base = 2  # segundos

        for attempt in range(1, max_retries + 1):
            success = force_download(path)

            # Validaci√≥n real de archivo descargado
            if success and path.exists() and path.is_file() and path.stat().st_size > 0:
                break

            print(f"üîÅ Retry {attempt}/{max_retries} para {path.name}...")
            sleep(delay_base * attempt)
        else:
            print(f"‚õî No se pudo acceder a: {file_path} tras {max_retries} intentos")
            return None, {}

        # Proceder con la lectura
        xls = pd.ExcelFile(file_path)
        raw_sheets = xls.sheet_names

        for s in raw_sheets:
            if s.lower().strip() in ("input", "datainput"):
                target = s
                break
        else:
            target = raw_sheets[0]

        df = pd.read_excel(xls, sheet_name=target, dtype=str, na_filter=False)
        df.columns = [clean_column_name(c) for c in df.columns]

        rename_dict = {}
        for col in COLUMNS:
            if col.get("source") != "input":
                continue
            try:
                real = get_column(df, col["key"])
                rename_dict[real] = col["key"]
            except KeyError:
                pass
        df = df.rename(columns=rename_dict)

        # 1Ô∏è‚É£  Normaliza dtypes (solo una vez)
        df = cast_dataframe(df)  # <- aqu√≠


        meta = extract_metadata_from_excel(file_path) or {}
        return df, meta

    except Exception as e:
        print(f"[ERROR] {file_path}: {e}")
        traceback.print_exc()
        return None, {}



def combine_files(base_path, filter_func=None, explicit_files=None):
    """Combina archivos XLSX de inventario forestal.

    Args:
        base_path (str/Path): Ruta base (se ignora si explicit_files est√° presente)
        filter_func (callable, optional): Funci√≥n para filtrar metadatos
        explicit_files (list, optional): Lista expl√≠cita de paths de archivos a procesar

    Returns:
        pd.DataFrame: DataFrame combinado
    """

    df_list = []
    all_files = []

    # Priorizar archivos expl√≠citos si existen
    if explicit_files:
        from core.paths import INVENTORY_BASE

        # üîß Armar rutas completas + limpiar nombres invisibles
        all_files = [INVENTORY_BASE / Path(f) for f in explicit_files]


        #print(f"üóÇÔ∏è Procesando {len(all_files)} archivos expl√≠citos")

    else:  # Modo autom√°tico: buscar en directorio
        base_path = Path(base_path)
        print(f"üìÅ Buscando archivos en: {base_path}")

        for root, _, files in os.walk(base_path):
            for f in files:
                if (f.lower().endswith(".xlsx")
                        and not f.startswith("~$")
                        and "combined_inventory" not in f.lower()):
                    all_files.append(Path(root) / f)

        print(f"üîç Encontrados {len(all_files)} archivos XLSX")

    if not all_files:
        print("‚ùå No hay archivos para procesar")
        return pd.DataFrame()

    print("‚öôÔ∏è Iniciando procesamiento de archivos...")
    for path in tqdm(all_files, unit="archivo"):
        # ‚¨áÔ∏è Verifica y descarga si est√° en la nube
        if not force_download(path):
            continue  # Silencioso

        file = path.name
        try:
            # Leer archivo y metadatos
            df, meta = read_metadata_and_input(path)

            if df is None:
                print(f"   ‚ö†Ô∏è  Archivo no procesado: {file}")
                continue

            if df.empty:
                print(f"   ‚ö†Ô∏è  Archivo vac√≠o: {file}")
                continue

            # Validaci√≥n b√°sica de columnas
            required_cols = ["tree_number", "Status"]
            missing = [c for c in required_cols if c not in df.columns]
            if missing:
                print(f"   ‚ùå Faltan columnas clave: {', '.join(missing)}")
                continue

            # Filtrado por metadatos
            if filter_func and not filter_func(meta):
                print(f"   üö´ Filtrado por c√≥digos: {file}")
                continue

            # Limpieza inicial
            df = df.dropna(subset=["tree_number", "Status"], how="all")
            df = df.reset_index(drop=True)

            # A√±adir metadatos
            df["contractcode"] = meta.get("contract_code", "DESCONOCIDO")
            df["farmername"] = meta.get("farmer_name", "SIN_NOMBRE")
            df["cruisedate"] = meta.get("cruise_date", pd.NaT)

            df_list.append(df)
            #print(f"   ‚úÖ Procesado exitoso: {len(df)} filas")

        except Exception as e:
            print(f"   üî• Error cr√≠tico en {file}: {str(e)}")
            continue

    if not df_list:
        print("‚ùå Ning√∫n archivo pudo ser procesado")
        return pd.DataFrame()

    combined = pd.concat(df_list, ignore_index=True)
    print("\nüìä Combinaci√≥n finalizada")
    print(f"üå≥ Total de √°rboles procesados: {len(combined):,}")
    #print(f"üìÖ Rango de fechas: {combined['cruisedate'].min()} a {combined['cruisedate'].max()}")

    return combined

