from utils.libs import os, pd, warnings
from utils.extractors import extract_metadata_from_excel
from utils.cleaners import clean_column_name, get_column

# Suprime warnings benignos de openpyxl
warnings.filterwarnings(
    "ignore",
    message="Data Validation extension is not supported and will be removed",
    category=UserWarning,
    module="openpyxl"
)
warnings.filterwarnings(
    "ignore",
    message="Conditional Formatting extension is not supported and will be removed",
    category=UserWarning,
    module="openpyxl"
)


def read_input_sheet(file_path):
    """
    Lee la hoja 'Input' o 'DataInput' y normaliza columnas
    usando √∫nicamente COLUMN_LOOKUP + get_column.
    """
    try:
        # 1) Selecciona la hoja correcta
        xls = pd.ExcelFile(file_path)
        sheets = xls.sheet_names
        target = next(
            (s for s in sheets if s.lower().strip() in ("input", "datainput")),
            sheets[0] if sheets else None
        )

        # 2) Lee el Excel crudo
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            df = pd.read_excel(
                file_path,
                sheet_name=target,
                engine="openpyxl",
                dtype=str,
                na_filter=False
            )

        print(f"\n=== DEBUG {os.path.basename(file_path)} ===")
        print("Columnas originales:", df.columns.tolist())

        # 3) Limpia todos los nombres de columna con tu normalizador
        df.columns = [clean_column_name(col) for col in df.columns]
        print("Columnas limpiadas:", df.columns.tolist())

        # 4) Define aqu√≠ los campos l√≥gicos que quieres capturar
        #    y el nombre interno que les vas a dar
        campos = {
            "Tree #": "tree_number",
            "Stand #": "stand",
            "Plot #": "plot",
            "Plot Coordinate": "plot_coordinate",
            "Status": "status_id",
            "Species": "species_id",
            "Defect": "defect_id",
            "Defect HT (ft)": "defect_ht_ft",
            "DBH (in)": "dbh_in",
            "THT (ft)": "tht_ft",
            "Merch. HT (ft)": "merch_ht_ft",
            "Pests": "pests_id",
            "Disease": "disease_id",
            "Coppiced": "coppiced_id",
            "Permanent Plot": "permanent_plot_id",
            "Short Note": "short_note",
            "ContractCode": "contractcode",
            "FarmerName": "farmername",
            "CruiseDate": "cruisedate"
        }

        # 5) Usa get_column para descubrir cada alias, y crea el dict de renombrado
        rename_dict = {}
        for logical_name, internal_name in campos.items():
            try:
                actual = get_column(df, logical_name)
                rename_dict[actual] = internal_name
            except KeyError:
                # si no lo encuentra, avisas o simplemente sigues
                print(f"‚ö†Ô∏è No encontr√© columna l√≥gica '{logical_name}'")

        # 6) Renombra de golpe
        df = df.rename(columns=rename_dict)
        print("Columnas tras renombrado:", df.columns.tolist())

        return df

    except Exception as e:
        print(f"[ERROR] No se pudo leer {file_path}: {e}")
        return None

def combine_files(base_path, filter_func=None):
    """
    Recorre base_path, procesa todos los .xlsx (excluye temporales y combinados),
    extrae metadatos y concatena DataFrames.
    """
    df_list = []

    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.lower().startswith("~$") or "combined_inventory" in file.lower():
                continue
            if not file.lower().endswith(".xlsx"):
                continue

            file_path = os.path.join(root, file)
            print(f"\nüìÑ Procesando archivo: {file}")

            # 1) Hojas
            xls = pd.ExcelFile(file_path)
            print(f"   ‚ñ∂ Hojas encontradas: {xls.sheet_names}")

            # 2) Metadata
            metadata = extract_metadata_from_excel(file_path) or {}
            print(f"   ‚ñ∂ Metadata extra√≠da: {metadata}")
            contract_code = metadata.get("contract_code")
            farmer_name  = metadata.get("farmer_name")
            cruise_date  = metadata.get("cruise_date", pd.NaT)

            # 3) Leer datos de la secci√≥n Input
            df = read_input_sheet(file_path)
            if df is None or df.empty:
                print(f"   ‚ö†Ô∏è Archivo omitido (sin datos v√°lidos): {file}")
                continue

            # 4) Validaciones
            if "tree_number" not in df.columns:
                print(f"üõë Error cr√≠tico: Columna 'tree_number' no encontrada en {file}")
                continue

            # 5) Asignar metadata
            df["contractcode"] = contract_code
            df["farmername"]   = farmer_name
            df["cruisedate"]   = cruise_date

            # 6) Debug: comprobar que la columna existe y est√° poblada
            print(f"   ‚ñ∂ Columns after metadata assign: {df.columns.tolist()}")
            print(f"   ‚ñ∂ Sample metadata row: {df[['contractcode','farmername','cruisedate']].iloc[0].to_dict()}")

            df_list.append(df)

    if not df_list:
        print("‚ùå No se encontr√≥ ning√∫n archivo v√°lido para combinar.")
        return None

    # 7) Concatenar y validar
    combined = pd.concat(df_list, ignore_index=True)
    print("\n=== FINAL COMBINED METADATA CHECK ===")
    print("Columns:", combined.columns.tolist())
    print("Unique contractcodes:", combined["contractcode"].dropna().unique()[:5])

    return combined

